{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0db41d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date\n",
    "import time\n",
    "import re\n",
    "#import seaborn as sns\n",
    "import datetime \n",
    "from  calendar import monthrange\n",
    "\n",
    "from flask import Flask, request, render_template\n",
    "app = Flask(__name__)\n",
    "\n",
    "#from products import products\n",
    "\n",
    "#Carga de información\n",
    "#Estadísticas de preferencias\n",
    "#Importando las librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date\n",
    "import pyodbc\n",
    "import time\n",
    "import re\n",
    "#import seaborn as sns\n",
    "import datetime \n",
    "from  calendar import monthrange\n",
    "\n",
    "def modeloriesgos(input_table_1,dir):\n",
    "\n",
    "    \n",
    "    plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "    def fxn():\n",
    "        warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "    d=dir\n",
    "    os.chdir(d)\n",
    "\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "    from IPython.display import Image as PImage\n",
    "    from subprocess import check_call\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    from pydotplus import graph_from_dot_data    \n",
    "\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.preprocessing  import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    from sklearn.model_selection import learning_curve\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    #from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import KFold, cross_val_score\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    import pickle\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        fxn()\n",
    "\n",
    "\n",
    "    ###prueba\n",
    "\n",
    "\n",
    "    def fecha_spanish(fecha):\n",
    "        mes=[]\n",
    "        if fecha[5:7]=='01':\n",
    "            mes='Ene'\n",
    "        elif fecha[5:7]=='02':\n",
    "            mes='Feb'\n",
    "        elif fecha[5:7]=='03':\n",
    "            mes='Mar'\n",
    "        elif fecha[5:7]=='04':\n",
    "            mes='Abr'\n",
    "        elif fecha[5:7]=='05':\n",
    "            mes='May'\n",
    "        elif fecha[5:7]=='06':\n",
    "            mes='Jun'\n",
    "        elif fecha[5:7]=='07':\n",
    "            mes='Jul'\n",
    "        elif fecha[5:7]=='08':\n",
    "            mes='Ago'\n",
    "        elif fecha[5:7]=='09':\n",
    "            mes='Set'\n",
    "        elif fecha[5:7]=='10':\n",
    "            mes='Oct'\n",
    "        elif fecha[5:7]=='11':\n",
    "            mes='Nov'\n",
    "        else:\n",
    "            mes='Dic'\n",
    "\n",
    "        return mes+fecha[2:4]\n",
    "\n",
    "\n",
    "    def last_day_of_month(date_value):\n",
    "        return date_value.replace(day = monthrange(date_value.year, date_value.month)[1])\n",
    "    \n",
    "    today = date.today()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    import dateutil.relativedelta\n",
    "\n",
    "  \n",
    "    ParametroFecha = today - dateutil.relativedelta.relativedelta(months=1)\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    ParametroFecha=last_day_of_month(last_day_of_month(today)-pd.DateOffset(months=1))\n",
    "    ParametroFecha=ParametroFecha.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "    folder='./Files_'+str(fecha_spanish(ParametroFecha))+'/'\n",
    "    #folder='./Files_Ene22/'\n",
    "    # Example\n",
    "\n",
    "    os.chdir(folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    input_table_1['Fechap']=pd.to_datetime(input_table_1['Fechap'])\n",
    "    \n",
    "    input_table_1=input_table_1[(input_table_1['Fechap'].apply(lambda x:last_day_of_month(x))==last_day_of_month(today).strftime(\"%Y-%m-%d\")) & (input_table_1['idEstado']==1)]\n",
    "    #input_table_1=input_table_1[(input_table_1['Fechap'].apply(lambda x:last_day_of_month(x))==last_day_of_month(today).strftime(\"%Y-%m-%d\")) & (input_table_1['idEstado']==1)]\n",
    "\n",
    "    input_table_1['FechaNacimiento']=pd.to_datetime(input_table_1['FechaNacimiento'])\n",
    "    input_table_1['Fecha_so']=input_table_1['Fechap']\n",
    "    input_table_1['plazo']=input_table_1['plazo_sol']\n",
    "    input_table_1['Edad']=round((input_table_1['Fechap']-  input_table_1['FechaNacimiento'])/np.timedelta64(1,'Y'),0)\n",
    "    input_table_1['Fecha_so']\n",
    "    \n",
    "    td= input_table_1.copy() \n",
    "    Result = pd.DataFrame()\n",
    "\n",
    "    # load the model from disk\n",
    "    pcafile='pca.sav'\n",
    "    filename = 'Modelo.sav'\n",
    "    prep='scaler.sav'\n",
    "    pca = pickle.load(open(pcafile, 'rb'))\n",
    "    lr = pickle.load(open(filename, 'rb'))\n",
    "    scaler = pickle.load(open(prep, 'rb'))\n",
    "\n",
    "\n",
    "    fecha=input_table_1['Fechap']\n",
    "    #obtiene datos especificos para el mapeo \n",
    "    final_features=pd.read_csv('features.csv')\n",
    "    final_features=final_features['Variables'].to_list()\n",
    "\n",
    "    variables_normalizar=pd.read_csv('variables_normalizar.csv')\n",
    "    variables_normalizar=variables_normalizar['Variables'].to_list()\n",
    "\n",
    "    pcas=pd.read_csv('pcas.csv')\n",
    "    pcas=pcas['pcas'].to_list()\n",
    "\n",
    "    td=td[[\n",
    "    'num_solicitud',\n",
    "    'Edad',\n",
    "    'Sexo',\n",
    "    'EstadoCivil',\n",
    "    'TipoVivienda',\n",
    "    'NivelInstruccion',\n",
    "    'Profesion',\n",
    "    'Departamento',\n",
    "    'telefono',\n",
    "    'NroDependientes',\n",
    "    'AniosResidencia',\n",
    "    'Fecha_so',\n",
    "    'Monto_sol',\n",
    "    'plazo'\n",
    "    ]]\n",
    "    \n",
    "    td['Monto_sol']=td['Monto_sol'].astype('float')\n",
    "    td['plazo']=td['plazo'].astype('float')\n",
    "    td['NroDependientes']=td['NroDependientes'].astype('int')\n",
    "    td['AniosResidencia']=td['AniosResidencia'].astype('int')\n",
    "\n",
    "    td = td.set_index('num_solicitud')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    features_c=td.select_dtypes(include='object').columns.tolist()\n",
    "    features_n=td.select_dtypes(exclude='object').columns.tolist()\n",
    "\n",
    "    features_n.remove('Fecha_so')\n",
    "    features_c.remove('telefono')\n",
    "\n",
    "    for label in features_c:\n",
    "        #print(label)\n",
    "        td[label].fillna(td[label].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    #Tratamiento de los datos\n",
    "\n",
    "    def TransformVariables2(Rango,valores):\n",
    "        for label in Rango:\n",
    "            for categoria in valores:\n",
    "                td[label+'_'+categoria]=np.where(td[label]==categoria,1,0)\n",
    "                td[label+'_'+categoria]=td[label+'_'+categoria].astype('O')\n",
    "\n",
    "        td[label+'_'+'OTROS']=np.where(td[label].apply(lambda x: x not in valores),1,0)        \n",
    "        td[label+'_'+'OTROS']=td[label+'_'+'OTROS'].astype('O') \n",
    "        td.drop([label],axis=1,inplace=True)\n",
    "\n",
    "    #Creación de la variable Dia de la semana\n",
    "    td['Fecha_so']=pd.to_datetime(td['Fecha_so'])\n",
    "    td['DiaSemana'] = td['Fecha_so'].dt.dayofweek\n",
    "    td['DiaSemana']=np.where(td['DiaSemana']==0,\"Otros\",np.where(td['DiaSemana']==1,\"Martes\",np.where(td['DiaSemana']==2,\"Miercoles\",np.where(td['DiaSemana']==3,\"Jueves\",np.where(td['DiaSemana']==4,\"Viernes\",np.where(td['DiaSemana']==5,\"Otros\",\"Otros\"))))))\n",
    "\n",
    "\n",
    "    #creación de variables\n",
    "\n",
    "    #td['Nombre_producto_sol']=np.where(td['Nombre_producto_sol'].str.lower().str.contains('pyme'),'PYME','CONN')\n",
    "\n",
    "    td['NumReferenciasTel']=td['telefono'].apply(lambda x:x.rstrip().lstrip().count(' ')+x.rstrip().lstrip().count(',')+x.rstrip().lstrip().count(';')+1)\n",
    "\n",
    "\n",
    "\n",
    "    td['Profesion']=np.where(td['Profesion'].isnull(),td['Profesion'],td['Profesion'].apply(lambda x: x.replace(',','').replace('/','').replace('(','').replace(')','')))\n",
    "\n",
    "    Rango=['DiaSemana']\n",
    "    valores=['Martes','Miercoles','Jueves','Viernes','Otros']\n",
    "    TransformVariables2(Rango,valores)\n",
    "\n",
    "    Rango=['Sexo']\n",
    "    valores=['MASCULINO','FEMENINO']\n",
    "    TransformVariables2(Rango,valores)\n",
    "\n",
    "    #1 \n",
    "    Rango=['Profesion']\n",
    "    valores=['COMERCIANTE  VENDEDOR','OTROS señalar','OBRERO  OPERADOR','ALBAÑIL OBRERO DE CONSTRUCCIÓN','CONDUCTOR CHOFER  TAXISTA','TRANSPORTISTA','AGRICULTOR AGRÓLOGO ARBORICULTOR GEÓGRAFO','GANADERO','ADMINISTRADOR','DOCENTE','AMA DE CASA','CAMPESINO']\n",
    "    TransformVariables2(Rango,valores)\n",
    "\n",
    "\n",
    "    #2\n",
    "    Rango=['NivelInstruccion']\n",
    "    valores=['SECUNDARIA COMPLETA','SECUNDARIA INCOMPLETA','SECUNDARIA','PRIMARIA COMPLETA','SUPERIOR NO UNIVERSITARIO','SUPERIOR UNIVERSITARIO','PRIMARIA INCOMPLETA','PRIMARIA']\n",
    "    TransformVariables2(Rango,valores)\n",
    "\n",
    "    #3\n",
    "    Rango=['Departamento']\n",
    "    valores=['HUANUCO','CUSCO','JUNIN','CAJAMARCA','AYACU+CHO','AREQUIPA','AMAZONAS','PUNO','PASCO','APURIMAC','TACNA','HUANCAVELICA']\n",
    "    TransformVariables2(Rango,valores)\n",
    "\n",
    "    #4\n",
    "    Rango=['TipoVivienda']\n",
    "    valores=['FAMILIAR','PROPIA AUTOFINANCIADO','ALQUILADO','PROPIA HEREDADA']\n",
    "    TransformVariables2(Rango,valores)\n",
    "\n",
    "    #5\n",
    "    Rango=['EstadoCivil']\n",
    "    valores=['SOLTERO(A)','CONVIVIENTE','CASADO(A)','VIUDO(A)','SEPARADO(A)','DIVORCIADO(A)']\n",
    "    TransformVariables2(Rango,valores)\n",
    "\n",
    "\n",
    "    td=td.drop(['telefono','Fecha_so'],axis=1)\n",
    "    features_c=td.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "\n",
    "    for label in features_n:\n",
    "        td[label].fillna(td[label].median(), inplace=True)\n",
    "\n",
    "    features_n_originales=features_n\n",
    "    #print('-----aqui')\n",
    "    #print(td.describe())   \n",
    "\n",
    "\n",
    "\n",
    "    for label in features_n:\n",
    "        trans_1=label+'_log'\n",
    "        trans_2=label+'_sqrt'\n",
    "        trans_3=label+'_power2'\n",
    "        trans_4=label+'_power3'\n",
    "\n",
    "        td[trans_1]=np.log(td[label]+1)\n",
    "        td[trans_2]=np.sqrt(td[label])\n",
    "        td[trans_3]=np.power(td[label],2)\n",
    "        td[trans_4]=np.power(td[label],3)\n",
    "\n",
    "    td.drop(['DiaSemana_OTROS','Sexo_OTROS'],axis=1,inplace=True)\n",
    "\n",
    "    features_n=td.select_dtypes(exclude='object').columns.tolist()\n",
    "\n",
    "    td=td.reset_index(inplace=False).sort_values(by='num_solicitud',ascending=True).set_index('num_solicitud')\n",
    "    X= td\n",
    "\n",
    "    columns=X.columns.tolist()\n",
    "\n",
    "\n",
    "    #print('Esto')\n",
    "    #X.to_excel ('validar_completo_auto.xlsx', index = True, header=True)\n",
    "    #################\n",
    "    #Split train/test \n",
    "    #################\n",
    "\n",
    "\n",
    "    x_train=X\n",
    "\n",
    "    #print(final_features)\n",
    "\n",
    "    #seleccionado las mejores variables transformadas\n",
    "\n",
    "    x_train_res=x_train[variables_normalizar]\n",
    "    #x_val=x_val[best_variables]\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    x_train_res_scal = scaler.transform(x_train_res)\n",
    "\n",
    "    x_train_res_scal=pd.DataFrame(x_train_res_scal,columns=x_train_res.columns.tolist())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    x= x_train_res_scal[final_features]\n",
    "\n",
    "      #Componentes Principales\n",
    "\n",
    "    principalComponentes = pca.transform(x)\n",
    "    x_pca=principalComponentes  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    x_train_pca=pd.DataFrame(x_pca,columns=pcas)\n",
    "\n",
    "    X=x_train_pca\n",
    "\n",
    "    predicciones=lr.predict_proba(x_train_pca)\n",
    "    predicciones = pd.DataFrame(predicciones, columns = lr.classes_)\n",
    "    predicciones=predicciones.loc[:,1:2]    \n",
    "\n",
    "    y_predict_train= lr.predict(X)\n",
    "    X['probabilidades']=predicciones\n",
    "    X['Predict']=np.where(y_predict_train==1,'Malo','Bueno')\n",
    "    X['Fecha']=today\n",
    "    X['FechaCarga']=date.today()\n",
    "    X['num_solicitud']=td.reset_index()['num_solicitud']\n",
    "    output_table_1=X[['Fecha','Predict','num_solicitud','probabilidades','FechaCarga']]\n",
    "    \n",
    "    \n",
    "    #dirección de la búsqueda#\n",
    "    \n",
    "    import urllib\n",
    "    from sqlalchemy import create_engine\n",
    "    server = '10.5.5.226'\n",
    "    database = 'BD_RIESGOS'\n",
    "    params =urllib.parse.quote_plus('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';PORT=1443;DATABASE='+database+';Trusted_Connection=yes;')\n",
    "    engine = create_engine(\"mssql+pyodbc:///?odbc_connect=%s\"%params)\n",
    "    output_table_1.to_sql('PL_PRUEBA',con=engine, if_exists='append', index=False)#LA BASE SE LLAMA PL_PRUEBA\n",
    "    return output_table_1 \n",
    "\n",
    "\n",
    "\n",
    "# Testing Route\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \n",
    "    return \"<h1>Rogger - Index</h1>\"\n",
    "\n",
    "# Testing Route\n",
    "@app.route('/modeloNoBancarizado', methods=['GET'])\n",
    "def getModelo():\n",
    "        \n",
    "    from urllib.parse import unquote\n",
    "    #decoded = unquote(t)\n",
    "    \n",
    "    num_solicitud = request.args.get('num_solicitud',0,type=int)\n",
    "    Fechap = request.args.get('Fechap','',type=str)\n",
    "    idEstado = request.args.get('idEstado',0,type=int)\n",
    "    Monto_sol = request.args.get('Monto_sol',0,type=float)\n",
    "    plazo_sol = request.args.get('plazo_sol',0,type=int)\n",
    "    FechaNacimiento = request.args.get('FechaNacimiento','',type=str)\n",
    "    Sexo = request.args.get('Sexo','',type=str)\n",
    "    EstadoCivil = request.args.get('EstadoCivil','',type=str)\n",
    "    TipoVivienda = request.args.get('TipoVivienda','',type=str)\n",
    "    NivelInstruccion = request.args.get('NivelInstruccion','',type=str)\n",
    "    Actividad = request.args.get('Actividad','',type=str)\n",
    "    Profesion = request.args.get('Profesion','',type=str)\n",
    "    Departamento = request.args.get('Departamento','',type=str)\n",
    "    telefono = request.args.get('telefono','',type=str)\n",
    "    NroDependientes = request.args.get('NroDependientes',0,type=int)\n",
    "    AniosResidencia = request.args.get('AniosResidencia',0,type=int)\n",
    "    \n",
    "    var_1=[num_solicitud]\n",
    "    var_2=[Fechap]\n",
    "    var_3=[idEstado]\n",
    "    var_4=[Monto_sol]\n",
    "    var_5=[plazo_sol]\n",
    "    var_6=[FechaNacimiento]\n",
    "    var_7=[Sexo]\n",
    "    var_8=[EstadoCivil]\n",
    "    var_9=[TipoVivienda]\n",
    "    var_10=[NivelInstruccion]\n",
    "    var_11=[Actividad]\n",
    "    var_12=[Profesion]\n",
    "    var_13=[Departamento]\n",
    "    var_14=[telefono]\n",
    "    var_15=[NroDependientes]\n",
    "    var_16=[AniosResidencia]\n",
    "    \n",
    "    #se crea una lista\n",
    "    df=[]\n",
    "    df.append(var_1)\n",
    "    df.append(var_2)\n",
    "    df.append(var_3)\n",
    "    df.append(var_4)\n",
    "    df.append(var_5)\n",
    "    df.append(var_6)\n",
    "    df.append(var_7)\n",
    "    df.append(var_8)\n",
    "    df.append(var_9)\n",
    "    df.append(var_10)\n",
    "    df.append(var_11)\n",
    "    df.append(var_12)\n",
    "    df.append(var_13)\n",
    "    df.append(var_14)\n",
    "    df.append(var_15)\n",
    "    df.append(var_16)\n",
    "    \n",
    "    df = pd.DataFrame (df).transpose()\n",
    "    df.columns=['num_solicitud','Fechap','idEstado','Monto_sol','plazo_sol',\n",
    "                'FechaNacimiento','Sexo','EstadoCivil','TipoVivienda','NivelInstruccion',\n",
    "                'Actividad','Profesion','Departamento','telefono','NroDependientes','AniosResidencia']\n",
    "    \n",
    "    modeloriesgos(df,\"D:/Modelo Grupo Solidario\")\n",
    "    \n",
    "    return \"<h1>Datos Procesados</h1>\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from waitress import serve\n",
    "    serve(app, host=\"0.0.0.0\", port=4000)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "9501f381cabf995a2935b6c3c0c0e62ae8da0146af789528b3967c2f18f30e95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
